{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "792872be-95dc-4f8d-9cac-1d7eae76a28a",
   "metadata": {},
   "source": [
    "# Cifar10 Dataset Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12693b3e-a66a-409d-bdc6-e414340ec0e2",
   "metadata": {},
   "source": [
    "## Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9869f64e-a692-42ff-a4f6-295600320eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Class names in CIFAR-10 dataset:\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.datasets import cifar10  # Import cifar10 from keras.datasets \n",
    "\n",
    "# Load the CIFAR-10 dataset using tensorflow_datasets\n",
    "dataset, info = tfds.load('cifar10', with_info=True)\n",
    "\n",
    "# Extract the class names from the dataset info\n",
    "class_names = info.features['label'].names\n",
    "\n",
    "# Print the class names\n",
    "print(\"Class names in CIFAR-10 dataset:\")\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c18ee9-fc34-4ce8-bf5f-fcde81cfc025",
   "metadata": {},
   "source": [
    "## Import necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6388dc38-a63f-4821-a4e4-3778048e254d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "751891cc-91bd-4795-a5ec-7176ac097756",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (50000, 32, 32, 3), Training labels shape: (50000, 1)\n",
      "Test data shape: (10000, 32, 32, 3), Test labels shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(f\"Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd9792c6-f0a5-4a5e-b909-fb63f2d5fd46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed training data shape: (50000, 1024)\n",
      "Transformed test data shape: (10000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the images :  Convert the images to grayscales by selecting the first color channel\n",
    "x_images_training = X_train[:, :, :, 0]  # Using the first channel\n",
    "x_train = x_images_training.reshape((X_train.shape[0], 32 * 32))  # Flattening images into 2D\n",
    "y_train = y_train.flatten()  # Flatten the labels\n",
    "\n",
    "x_images_test = X_test[:, :, :, 0]  # Using the first channel for test set\n",
    "x_test = x_images_test.reshape((X_test.shape[0], 32 * 32))  # Flattening images into 2D\n",
    "y_test = y_test.flatten()  # Flatten the labels\n",
    "\n",
    "# Print transformed shapes\n",
    "print(f\"Transformed training data shape: {x_train.shape}\")\n",
    "print(f\"Transformed test data shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ec89c-479e-420c-956c-86fbd5012f29",
   "metadata": {},
   "source": [
    "## Apply PCA to reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ff94aa-83bc-4dca-9369-44277830ffc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components after PCA: 429\n",
      "PCA-transformed training data shape: (50000, 429)\n",
      "PCA-transformed test data shape: (10000, 429)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to reduce dimensionality, retaining 99% of the variance\n",
    "pca = PCA(whiten=True)\n",
    "pca.fit(x_train)\n",
    "total_variance = sum(pca.explained_variance_)\n",
    "k = 0\n",
    "current_variance = 0\n",
    "\n",
    "# Calculate the number of components needed to preserve 99% of the variance\n",
    "while current_variance / total_variance < 0.99:\n",
    "    current_variance += pca.explained_variance_[k]\n",
    "    k += 1\n",
    "\n",
    "print(f\"Number of components after PCA: {k}\")\n",
    "\n",
    "# Transform training and test data using PCA\n",
    "pca_cifar = PCA(n_components=k, whiten=True)\n",
    "x_train_transformed = pca_cifar.fit_transform(x_train)\n",
    "x_test_transformed = pca_cifar.transform(x_test)\n",
    "\n",
    "# Print shapes after PCA transformation\n",
    "print(f\"PCA-transformed training data shape: {x_train_transformed.shape}\")\n",
    "print(f\"PCA-transformed test data shape: {x_test_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fc52b7-fd2e-4ac7-bc9a-34f87b596106",
   "metadata": {},
   "source": [
    "## Initialize Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4229a5b-5c5f-4e7d-b765-d549154afb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "clf1 = RandomForestClassifier(n_estimators=k, n_jobs=-1, max_depth=2000, max_leaf_nodes=2350)\n",
    "clf2 = LogisticRegression(n_jobs=-1, multi_class=\"auto\", solver='lbfgs', max_iter=1000)\n",
    "clf3 = KNeighborsClassifier(n_jobs=-1)\n",
    "clf4 = SVC(tol=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51654c84-9c59-4424-bdae-b7af6ba8f1cc",
   "metadata": {},
   "source": [
    "## Training Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dccad95e-145b-4f55-a4a5-e5838b158453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifiers...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Train the classifiers\n",
    "print(\"Training classifiers...\")\n",
    "clf1.fit(x_train_transformed, y_train)\n",
    "clf2.fit(x_train_transformed, y_train)\n",
    "clf3.fit(x_train_transformed, y_train)\n",
    "clf4.fit(x_train_transformed, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5de1a5-a35e-40c8-b9b4-d7debab965e5",
   "metadata": {},
   "source": [
    "## Testing the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcf31671-8190-4e68-9ff5-33ab7072368d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data...\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "print(\"Predicting on test data...\")\n",
    "y_test_predicted1 = clf1.predict(x_test_transformed)\n",
    "y_test_predicted2 = clf2.predict(x_test_transformed)\n",
    "y_test_predicted3 = clf3.predict(x_test_transformed)\n",
    "y_test_predicted4 = clf4.predict(x_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138cc5c-be2d-41bd-8e72-560d3ef549e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d3c3a0-07a8-458d-be76-7f84bdf6431c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Voting mechanism for final predictions\n",
    "dic = {i: class_names[i] for i in range(len(class_names))}\n",
    "ans = []\n",
    "\n",
    "for i in range(len(y_test_predicted1)):\n",
    "    arr = np.array([y_test_predicted1[i], y_test_predicted2[i], y_test_predicted3[i], y_test_predicted4[i]])\n",
    "    ans.append(dic[np.argmax(np.bincount(arr))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9d203-1f27-44e8-b199-0c953db82f69",
   "metadata": {},
   "source": [
    "## Calculate accuracy for the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c18cd1-5889-429f-ad05-9700f797eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ensemble model: 35.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_test_class_names = [class_names[i] for i in y_test]\n",
    "accuracy = accuracy_score(y_test_class_names, ans)\n",
    "\n",
    "print(f\"Accuracy of the ensemble model: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79486f1-7490-4958-94ed-6a22f45e9e59",
   "metadata": {},
   "source": [
    "# Save predictions to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9410a283-ce66-40b7-92ad-39d1cf424848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'answers.csv'.\n"
     ]
    }
   ],
   "source": [
    "np.savetxt(fname=\"answers.csv\", X=ans, delimiter=',', fmt=\"%s\")\n",
    "print(\"Predictions saved to 'answers.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235640aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
